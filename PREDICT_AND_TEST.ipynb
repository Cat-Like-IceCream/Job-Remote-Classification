{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eacbfc-c756-4156-a6f4-3af26ad89514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eaa81-647a-4ec9-958f-8381fb744170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case = True\n",
    "    )\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "\"001Model\"\n",
    ").to(device)\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "\n",
    "    return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d9217-8984-4740-b39f-6285db804f28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test for one description\n",
    "\n",
    "new_sentence = '''\n",
    "Part Time Assistant Manager 8055 W Bowles Ave  Store 0013  Tuesday Morning  Littleton, CO Tuesday Morning    Job Company  Job details  Salary 14.35  23.00 an hour Job Type Parttime  Full Job Description  Tuesday Morning is taking the lead in offprice retail offering upscale decorative home accessories, housewares, seasonal goods and famousmaker gifts.  Our mission is simple offer fresh and exciting merchandise at unbelievable value, with impeccable service.  With over 750 stores in 40 states, and continuing to grow, we are always seeking strong leadership to fuel our growth.  The Part Time Assistant Store Managers role is to, take the lead from and, partner with the Store Manager to engage, motivate and lead a team of associates in operating a profitable store, while creating a positive environment for the associate and the guest. The Assistant Store Manager is the extension of the Store Manager and will provide overall support to drive the Store Managers vision and direction for the store.  Responsibilities  Sales Driving sales by creating a sales generating environment through the implementation of all corporate sales directives. Service Foster a service oriented environment tailored to the unique seeker, and ensuring the guest is always taken care of the right way. Merchandise Ensure Merchandising standards and product presentations are second to none, and create that WOW factor. Leadership Provide ongoing coaching feedback, empowering your team to do whats right, setting clear expectations and leading by example. Communication Set the vision and direction for the store, share information to align your team  help them feel a part of something big.  Skills  experience  23 years of progressively responsible retail, and at least 1 year of supervision, experience required. Must understand and be able to execute concepts related to financial principles, inventory management, and merchandising. Bachelors degree preferred. Possess strong leadership skills with the ability to train, coach and mentor associates with professional maturity. Ability to make decisions, communicate, analyze financial information, problem solve, organization and computer skills. Must be 21 years of age. Ability to relocate, for future growth and promotional opportunities, strongly desired.  We offer competitive compensation, excellent benefits to include 401k, bestinclass products and more, in a high performing environment. Working in our stores provides you with unlimited possibilities to start or expand your career.  Pay Range 14.35  23.00hr  Benefits  Join Tuesday Morning and enjoy  Some of the best hours in retail 401K 20 Associate discount Rewarding career with advancement opportunities  CB  Tuesday Morning \n",
    "'''\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0).to(device)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773fd30-51ab-4930-a542-1e153358b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Predictions\n",
    "with torch.no_grad():\n",
    "  output = model(test_ids, token_type_ids = None, attention_mask = test_attention_mask)\n",
    "\n",
    "prediction = 'remote' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'non-remote'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef708508-aaf1-4e19-8d34-5f4d302760e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run on Test Set\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = text.split()  # Split the text into words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)  # Join the remaining words back into a string\n",
    "\n",
    "df=pd.read_csv(\"test_set.csv\",nrows=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e0f37-d230-4352-a0dc-b069cfa60a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess\n",
    "def preprocess_string(input_string):\n",
    "    # Use regular expression to remove non-space, non-letter, non-number, non-comma, non-period, and non-question mark characters\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\s,.\\?]', '', input_string)\n",
    "    \n",
    "    return cleaned_string\n",
    "\n",
    "df['input1'] = df['input1'].apply(preprocess_string)\n",
    "df['input1'] = df['input1'].apply(remove_stopwords)\n",
    "\n",
    "df.rename(columns={'input1': 'text'}, inplace=True)\n",
    "df.rename(columns={'output1': 'label'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87c235-ed7f-4861-ba0d-173475182959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting into 100 word chunks for each description makes the model run faster. \n",
    "#A prediction of \"remote\" means at least one chunk is classified as remote.\n",
    "def split_into_100_words_each(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    result = []\n",
    "    current_chunk = []\n",
    "    word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        word_count += 1\n",
    "\n",
    "        if word_count >= 300:\n",
    "            result.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "            word_count = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        result.append(' '.join(current_chunk))\n",
    "    while len(result) < 3:\n",
    "        result.append(\"-999\")\n",
    "    while len(result) > 3:\n",
    "        result.pop()\n",
    "    return result\n",
    "\n",
    "#Some data processing that combine the chunk columns into one dataframe\n",
    "df['split_text'] = df['text'].apply(split_into_100_words_each)\n",
    "df['split_text'].to_list()\n",
    "df[['input1', 'input2', 'input3']] = pd.DataFrame(df['split_text'].to_list(), index=df.index)\n",
    "df.drop([\"split_text\",\"text\",\"Unnamed: 0\"],axis=1, inplace=True)\n",
    "df[\"job_id\"]=df.index\n",
    "df1= df[[\"job_id\",'label', 'input1']]\n",
    "df2= df[[\"job_id\",'label', 'input2']]\n",
    "df3= df[[\"job_id\",'label', 'input3']]\n",
    "df2 = df2.rename(columns={ 'input2': 'input1'})\n",
    "df3 = df3.rename(columns={ 'input3': 'input1'})\n",
    "df = pd.concat([df1, df2, df3],axis=0)\n",
    "df = df[df['input1'] != \"-999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc55d0-a9ea-453d-bfdb-fe0c0adc3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3 = df3.rename(columns={ 'input3': 'input1'})\n",
    "df = pd.concat([df1, df2, df3],axis=0)\n",
    "df = df[df['input1'] != \"-999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe301c-72cc-4c84-b5ef-e37bfa763a41",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for i in df[\"input1\"]:\n",
    "    new_sentence = i\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "    test_ids = []\n",
    "    test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "    encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "    test_ids.append(encoding['input_ids'])\n",
    "    test_attention_mask.append(encoding['attention_mask'])\n",
    "    test_ids = torch.cat(test_ids, dim = 0).to(device)\n",
    "    test_attention_mask = torch.cat(test_attention_mask, dim = 0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(test_ids, token_type_ids = None, attention_mask = test_attention_mask)\n",
    "    pred.append(np.argmax(output.logits.cpu().numpy()).flatten().item())\n",
    "    print(np.argmax(output.logits.cpu().numpy()).flatten().item())\n",
    "df[\"pred\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fb77e-a69a-4a84-b860-a8cda1c88430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"input1\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d89d06-da6f-477c-b305-d7d555093ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.groupby('job_id')[['pred',\"label\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570200c-c64d-4fa4-b69d-3156d708884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['pred'] = result['pred'].apply(lambda x: 1 if x > 1 else x)\n",
    "result['label'] = result['label'].apply(lambda x: 1 if x > 1 else x)\n",
    "df=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61875b77-0b4b-4506-859a-b6191808dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_same_values = (df['pred'] == df['label']).sum()\n",
    "count_same_values/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6cb1ac-eb99-4984-9923-6f61b564b7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
